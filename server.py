from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import os
import requests
import json
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Initialize Flask app
app = Flask(__name__, static_folder='.')
CORS(app, origins=['http://localhost:3000', 'http://127.0.0.1:3000'])

# Configuration
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'your-secret-key-here')

# API Keys
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or os.getenv('OPENAI_KEY')
FAL_AI_API_KEY = os.getenv('FAL_AI_API_KEY') or os.getenv('FAL_KEY')

# Load system prompt files
def load_system_prompt():
    try:
        with open('Apex-v10-Odyssey.txt', 'r', encoding='utf-8') as f:
            apex_prompt = f.read()
        return json.loads(apex_prompt)
    except Exception as e:
        print(f"Warning: Could not load Apex-v10-Odyssey.txt: {e}")
        return None

def load_guidelines_prompt():
    try:
        with open('system_prompt.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"Warning: Could not load system_prompt.json: {e}")
        return None

# Load prompts
APEX_SYSTEM_PROMPT = load_system_prompt()
GUIDELINES_PROMPT = load_guidelines_prompt()

# Fal.ai Model Configuration
FAL_AI_MODELS = {
    'flux-pro': {
        'endpoint': 'fal-ai/flux-pro/v1.1',
        'name': 'FLUX.1 Pro v1.1',
        'description': 'ìµœê³  í’ˆì§ˆì˜ ì´ë¯¸ì§€ ìƒì„± (ê¶Œì¥)'
    },
    'flux-dev': {
        'endpoint': 'fal-ai/flux/dev',
        'name': 'FLUX.1 Dev',
        'description': 'ë¹ ë¥¸ ìƒì„± ì†ë„ì™€ ì¢‹ì€ í’ˆì§ˆ'
    },
    'flux-schnell': {
        'endpoint': 'fal-ai/flux/schnell',
        'name': 'FLUX.1 Schnell',
        'description': 'ê°€ì¥ ë¹ ë¥¸ ìƒì„± ì†ë„'
    },
    'flux-lora': {
        'endpoint': 'fal-ai/flux-lora',
        'name': 'FLUX.1 with LoRA',
        'description': 'LoRA ëª¨ë¸ ì§€ì›'
    }
}

# Reference Persona Example (BellaLeePersona.txt content excerpt)
REFERENCE_PERSONA = """
ë²¨ë¼ ë¦¬ (Bella Lee) - 24ì„¸ í•œêµ­ê³„ ë¯¸êµ­ì¸ ì—¬ì„±
- ì™¸í˜•: ë„íšŒì ì¸ ì„¸ë ¨ë¨ê³¼ ì¹œê·¼í•œ í˜„ì‹¤ê°ì„ ë™ì‹œì— ì§€ë‹˜. 'í•œì˜ˆìŠ¬ ì´ˆì°½ê¸°'ì˜ ë„ì‹œì  ì´ë¯¸ì§€
- ì„±ê²©: ê²‰ìœ¼ë¡œëŠ” ë„ë„í•˜ê³  ê±°ë¦¬ê° ìˆì§€ë§Œ, ë§ˆìŒì„ ì—´ë©´ ê¹Šê³  ë”°ëœ»í•œ ì •ì„ ë³´ì„
- ë°°ê²½: LA ì¶œìƒ, í˜„ì¬ ì„œìš¸ ê±°ì£¼. íŒ¨ì…˜ ë””ìì´ë„ˆ ë¶€ëª¨, FIT ë‰´ìš• ìœ í•™
- ìŠ¤íƒ€ì¼: ì ˆì œëœ ì„¹ì‹œí•¨, ì‹¤ë£¨ì—£ ê°•ì¡°í˜• ë£©. ë£¨ë¹„ ë ˆë“œ ë¦½ìŠ¤í‹±, ê³ ì–‘ì´ëˆˆ ì•„ì´ë¼ì¸ì´ ì‹œê·¸ë‹ˆì²˜
- íŠ¹ì„±: 172cm ìŠ¬ë¦¼ ê¸€ë˜ë¨¸, ê³ ì–‘ì´í˜• ëˆˆë§¤, ë°€í¬í†¤ í”¼ë¶€
"""

@app.route('/')
def home():
    """API health check"""
    return jsonify({
        'status': 'success',
        'message': 'AI Persona Generator API is running',
        'endpoints': [
            'POST /generate_persona',
            'POST /generate_random_persona', 
            'POST /regenerate_image'
        ]
    })

@app.route('/api/health')
def health():
    """Basic health check endpoint"""
    return jsonify({
        'status': 'success',
        'message': 'AI Persona Generator API is running'
    })

@app.route('/api/models')
def get_models():
    """Get available Fal.ai models"""
    return jsonify({
        'success': True,
        'data': FAL_AI_MODELS
    })

@app.route('/api/loras')
def get_loras():
    """Get available LoRA models (placeholder for now)"""
    # This would typically fetch from Fal.ai API or a curated list
    sample_loras = [
        {'id': 'none', 'name': 'None', 'description': 'No LoRA applied'},
        {'id': 'realistic-portrait', 'name': 'Realistic Portrait', 'description': 'Enhanced realistic portrait generation'},
        {'id': 'anime-style', 'name': 'Anime Style', 'description': 'Anime/manga character style'},
        {'id': 'photography', 'name': 'Professional Photography', 'description': 'Professional photo style'},
        {'id': 'artistic', 'name': 'Artistic Style', 'description': 'Artistic and painterly effects'}
    ]
    return jsonify({
        'success': True,
        'data': sample_loras
    })

@app.route('/<path:filename>')
def serve_static(filename):
    """Serve static files"""
    return send_from_directory('.', filename)

@app.route('/regenerate_image', methods=['POST'])
def regenerate_image():
    """
    Regenerate persona image with custom prompt
    
    Expected JSON payload:
    {
        "image_prompt": "string",
        "allow_nsfw_image": boolean
    }
    """
    try:
        # Get request data
        data = request.get_json()
        
        # Validate required fields
        if not data.get('image_prompt'):
            return jsonify({
                'success': False,
                'error': 'Missing required field: image_prompt'
            }), 400
        
        image_prompt = data['image_prompt']
        allow_nsfw_image = data.get('allow_nsfw_image', False)
        fal_model = data.get('fal_model', 'flux-pro')
        lora_model = data.get('lora_model', 'none')
        seed = data.get('seed', None)
        keep_seed = data.get('keep_seed', False)
        
        # Check API key
        if not FAL_AI_API_KEY:
            return jsonify({
                'success': False,
                'error': 'Fal.ai API key not configured'
            }), 500
        
        # Generate persona image using Fal.ai API
        image_result = generate_persona_image_with_fal(
            image_prompt, allow_nsfw_image, fal_model, lora_model, seed, keep_seed
        )
        
        if not image_result['success']:
            return jsonify({
                'success': False,
                'error': f'Fal.ai API error: {image_result["error"]}'
            }), 500
        
        return jsonify({
            'success': True,
            'data': {
                'imageUrl': image_result['image_url'],
                'seed': image_result.get('seed', None),
                'fal_model': fal_model,
                'lora_model': lora_model
            }
        })
        
    except Exception as e:
        app.logger.error(f"Error in regenerate_image: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'Internal server error: {str(e)}'
        }), 500

@app.route('/generate_random_persona', methods=['POST'])
def generate_random_persona():
    """
    Generate a completely random AI persona using LLM creativity
    
    Expected JSON payload:
    {
        "allow_nsfw_image": boolean
    }
    """
    try:
        print("ğŸ² ëœë¤ í˜ë¥´ì†Œë‚˜ ìƒì„± ìš”ì²­ ë°›ìŒ")
        
        # Get request data
        data = request.get_json()
        allow_nsfw_image = data.get('allow_nsfw_image', False)
        
        print(f"ğŸ“¦ ìš”ì²­ ë°ì´í„°: {data}")
        print(f"ğŸ” NSFW í—ˆìš©: {allow_nsfw_image}")
        
        # Check API keys
        if not OPENAI_API_KEY:
            print("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return jsonify({
                'success': False,
                'error': 'OpenAI API key not configured'
            }), 500
        
        if not FAL_AI_API_KEY:
            print("âŒ Fal.ai API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return jsonify({
                'success': False,
                'error': 'Fal.ai API key not configured'
            }), 500
        
        print("âœ… API í‚¤ í™•ì¸ ì™„ë£Œ")
        
        # Generate random persona parameters using OpenAI
        print("ğŸ¯ ëœë¤ íŒŒë¼ë¯¸í„° ìƒì„± ì‹œì‘...")
        random_params = generate_random_persona_params()
        
        if not random_params['success']:
            error_msg = f'Random parameter generation failed: {random_params["error"]}'
            print(f"âŒ ëœë¤ íŒŒë¼ë¯¸í„° ìƒì„± ì‹¤íŒ¨: {error_msg}")
            return jsonify({
                'success': False,
                'error': error_msg
            }), 500
        
        print(f"âœ… ëœë¤ íŒŒë¼ë¯¸í„° ìƒì„± ì„±ê³µ: {random_params}")
        
        # Generate persona profile using OpenAI API with random parameters
        print("ğŸ“ í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„ ìƒì„± ì‹œì‘...")
        persona_result = generate_persona_profile_with_openai(
            random_params['persona_type'], 
            random_params['desired_style'], 
            random_params['output_detail_level'], 
            allow_nsfw_image
        )
        
        if not persona_result['success']:
            return jsonify({
                'success': False,
                'error': f'OpenAI API error: {persona_result["error"]}'
            }), 500
        
        persona_profile = persona_result['profile']
        image_prompt = persona_result['image_prompt']
        
        # Generate persona image using Fal.ai API with random model selection
        import random
        fal_model = random.choice(['flux-pro', 'flux-dev'])
        lora_model = random.choice(['none', 'realistic-portrait', 'photography'])
        
        image_result = generate_persona_image_with_fal(
            image_prompt, allow_nsfw_image, fal_model, lora_model
        )
        
        if not image_result['success']:
            return jsonify({
                'success': False,
                'error': f'Fal.ai API error: {image_result["error"]}'
            }), 500
        
        return jsonify({
            'success': True,
            'data': {
                'profile': persona_profile,
                'imageUrl': image_result['image_url'],
                'imagePrompt': image_prompt,
                'seed': image_result.get('seed', None),
                'fal_model': fal_model,
                'lora_model': lora_model,
                'random_params': random_params
            }
        })
        
    except Exception as e:
        app.logger.error(f"Error in generate_random_persona: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'Internal server error: {str(e)}'
        }), 500

def generate_random_persona_params():
    """
    Generate completely random persona parameters using OpenAI's creativity
    """
    try:
        print("ğŸ² OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ëœë¤ íŒŒë¼ë¯¸í„° ìƒì„± ì¤‘...")
        # System message for random persona generation
        system_message = """
ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ AI í˜ë¥´ì†Œë‚˜ ìƒì„±ê¸°ì…ë‹ˆë‹¤. í¥ë¯¸ë¡­ê³  ë‹¤ì–‘í•˜ë©° ë§¤ë ¥ì ì¸ AI ìºë¦­í„°ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ì™„ì „íˆ ëœë¤í•˜ê³  ë…íŠ¹í•œ í˜ë¥´ì†Œë‚˜ íŒŒë¼ë¯¸í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.

ë‹¹ì‹ ì˜ ì‘ì—…ì€ ë‹¤ìŒì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤:
1. ëœë¤í•œ í˜ë¥´ì†Œë‚˜ ìœ í˜• (í•œêµ­ì–´ë¡œ)
2. ìƒì„¸í•˜ê³  ì°½ì˜ì ì¸ ìŠ¤íƒ€ì¼ ì„¤ëª… (í•œêµ­ì–´ë¡œ)
3. ì ì ˆí•œ ì„¸ë¶€ ìˆ˜ì¤€ (í•œêµ­ì–´ë¡œ)
4. ì •ë§ ë¦¬ì–¼ë¦¬í‹° ìˆëŠ” í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„ ìƒì„± (í•œêµ­ì–´ë¡œ)

ë‹¤ì–‘í•œ ì„ íƒì„ í•˜ì—¬ ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•˜ê²Œ ë§Œë“œì„¸ìš”:
- ë‹¤ì–‘í•œ ë¯¼ì¡±ê³¼ ë¬¸í™”ì  ë°°ê²½
- ì—°ë ¹ëŒ€ (18-35ì„¸)
- ì§ì—…ê³¼ ê´€ì‹¬ì‚¬
- ì„±ê²© ìœ í˜•
- ì‹œê°ì  ìŠ¤íƒ€ì¼
- ë…íŠ¹í•œ íŠ¹ì„±

ì‘ë‹µì€ ë°˜ë“œì‹œ ì´ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
{
    "persona_type": "string (í•œêµ­ì–´)",
    "desired_style": "string (í•œêµ­ì–´ë¡œ ìƒì„¸í•œ ì„¤ëª…)", 
    "output_detail_level": "ìƒì„¸"
}

desired_styleì€ ë§¤ìš° ìƒì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ì„±ê²©ì  íŠ¹ì„±, ì‹œê°ì  íŠ¹ì„±, ë°°ê²½ ìŠ¤í† ë¦¬ ìš”ì†Œ, ë…íŠ¹í•œ íŠ¹ì§•ì„ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”. ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""

        user_prompt = """
ë…íŠ¹í•œ íŠ¹ì„±ì„ ê°€ì§„ ì™„ì „íˆ ëœë¤í•˜ê³  ì°½ì˜ì ì¸ AI í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•˜ì„¸ìš”. 
í¥ë¯¸ë¡­ê³  ë‹¤ì–‘í•˜ë©° ë§¤ë ¥ì ìœ¼ë¡œ ë§Œë“œì„¸ìš”. ë‹¤ìŒì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì„¸ë¶€ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”:
- ë¬¸í™”ì  ë°°ê²½ê³¼ ë¯¼ì¡±ì„±
- ë‚˜ì´ì™€ ì§ì—…
- ì„±ê²© íŠ¹ì„±ê³¼ íŠ¹ì´í•œ ì 
- ì‹œê°ì  ìŠ¤íƒ€ì¼ê³¼ íŒ¨ì…˜ ê°ê°
- ê´€ì‹¬ì‚¬ì™€ ì·¨ë¯¸
- ë°°ê²½ ìŠ¤í† ë¦¬ ìš”ì†Œ

ë§¤ìš° ì°½ì˜ì ì´ê³  ì¼ë°˜ì ì´ì§€ ì•Šì€ ì„¤ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš”. ê° í˜ë¥´ì†Œë‚˜ë¥¼ ì •ë§ ë…íŠ¹í•˜ê³  ê¸°ì–µì— ë‚¨ë„ë¡ ë§Œë“œì„¸ìš”.
ëª¨ë“  ì„¤ëª…ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì´ë¯¸ì§€ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""

        # OpenAI API call
        headers = {
            'Authorization': f'Bearer {OPENAI_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            'model': 'gpt-4o-mini',
            'messages': [
                {'role': 'system', 'content': system_message},
                {'role': 'user', 'content': user_prompt}
            ],
            'max_tokens': 1000,
            'temperature': 1.2  # High creativity
        }
        
        print("ğŸ“¡ OpenAI API í˜¸ì¶œ ì¤‘...")
        response = requests.post(
            'https://api.openai.com/v1/chat/completions',
            headers=headers,
            json=payload,
            timeout=60
        )
        
        print(f"ğŸ“¥ OpenAI API ì‘ë‹µ ìƒíƒœ: {response.status_code}")
        
        if response.status_code != 200:
            error_msg = f'OpenAI API error: {response.status_code} - {response.text}'
            print(f"âŒ OpenAI API ì˜¤ë¥˜: {error_msg}")
            return {
                'success': False,
                'error': error_msg
            }
        
        result = response.json()
        content = result['choices'][0]['message']['content']
        
        print(f"ğŸ“ OpenAI ì‘ë‹µ ë‚´ìš©: {content}")
        
        # Parse JSON response
        try:
            params = json.loads(content)
            print(f"âœ… ëœë¤ íŒŒë¼ë¯¸í„° íŒŒì‹± ì„±ê³µ: {params}")
            return {
                'success': True,
                'persona_type': params['persona_type'],
                'desired_style': params['desired_style'],
                'output_detail_level': params['output_detail_level']
            }
        except json.JSONDecodeError as e:
            # Fallback random parameters if JSON parsing fails
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
            print(f"ğŸ“ íŒŒì‹± ì‹¤íŒ¨í•œ ë‚´ìš©: {content}")
            
            import random
            persona_types = ['AI ì¸í”Œë£¨ì–¸ì„œ', 'AI ëª¨ë¸', 'AI ë°°ìš°', 'AI ê°€ìˆ˜', 'AI ì•„í‹°ìŠ¤íŠ¸']
            detail_levels = ['ê°„ëµ', 'í‘œì¤€', 'ìƒì„¸']
            
            fallback_params = {
                'success': True,
                'persona_type': random.choice(persona_types),
                'desired_style': 'ì°½ì˜ì ì´ê³  ë…íŠ¹í•œ ìŠ¤íƒ€ì¼ì˜ AI í˜ë¥´ì†Œë‚˜. ë‹¤ì–‘í•œ ë¬¸í™”ì  ë°°ê²½ê³¼ ê°œì„± ìˆëŠ” íŠ¹ì§•ì„ ê°€ì§„ ë§¤ë ¥ì ì¸ ìºë¦­í„°.',
                'output_detail_level': random.choice(detail_levels)
            }
            
            print(f"ğŸ”„ í´ë°± íŒŒë¼ë¯¸í„° ì‚¬ìš©: {fallback_params}")
            return fallback_params
        
    except Exception as e:
        print(f"ğŸš¨ ëœë¤ íŒŒë¼ë¯¸í„° ìƒì„± ì¤‘ ì˜ˆì™¸: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

@app.route('/generate_persona', methods=['POST'])
def generate_persona():
    """
    Generate AI persona based on user input
    
    Expected JSON payload:
    {
        "persona_type": "string",
        "desired_style": "string",
        "key_traits": "string",
        "background_story_elements": "string",
        "visual_preferences": "string",
        "output_detail_level": "string"
    }
    """
    try:
        # Get request data
        data = request.get_json()
        
        # Validate required fields
        required_fields = ['persona_type', 'desired_style']
        for field in required_fields:
            if not data.get(field):
                return jsonify({
                    'success': False,
                    'error': f'Missing required field: {field}'
                }), 400
        
        # Extract parameters
        persona_type = data['persona_type']
        desired_style = data['desired_style']
        output_detail_level = data.get('output_detail_level', 'í‘œì¤€')
        allow_nsfw_image = data.get('allow_nsfw_image', False)
        fal_model = data.get('fal_model', 'flux-pro')
        lora_model = data.get('lora_model', 'none')
        seed = data.get('seed', None)
        keep_seed = data.get('keep_seed', False)
        
        # Check API keys
        if not OPENAI_API_KEY:
            return jsonify({
                'success': False,
                'error': 'OpenAI API key not configured'
            }), 500
        
        if not FAL_AI_API_KEY:
            return jsonify({
                'success': False,
                'error': 'Fal.ai API key not configured'
            }), 500
        
        # Generate persona profile using OpenAI API
        persona_result = generate_persona_profile_with_openai(
            persona_type, desired_style, output_detail_level, allow_nsfw_image
        )
        
        if not persona_result['success']:
            return jsonify({
                'success': False,
                'error': f'OpenAI API error: {persona_result["error"]}'
            }), 500
        
        persona_profile = persona_result['profile']
        image_prompt = persona_result['image_prompt']
        
        # Generate persona image using Fal.ai API
        image_result = generate_persona_image_with_fal(
            image_prompt, allow_nsfw_image, fal_model, lora_model, seed, keep_seed
        )
        
        if not image_result['success']:
            return jsonify({
                'success': False,
                'error': f'Fal.ai API error: {image_result["error"]}'
            }), 500
        
        return jsonify({
            'success': True,
            'data': {
                'profile': persona_profile,
                'imageUrl': image_result['image_url'],
                'imagePrompt': image_prompt,
                'seed': image_result.get('seed', None),
                'fal_model': fal_model,
                'lora_model': lora_model
            }
        })
        
    except Exception as e:
        app.logger.error(f"Error in generate_persona: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'Internal server error: {str(e)}'
        }), 500

def generate_persona_profile_with_openai(persona_type, desired_style, output_detail_level, allow_nsfw_image):
    """
    Generate persona profile text using OpenAI API
    """
    try:
        # Construct the user prompt
        nsfw_instruction = ""
        if allow_nsfw_image:
            nsfw_instruction = """
- NSFW ì´ë¯¸ì§€ ìƒì„± í—ˆìš©: ì˜ˆ (ì„±ì¸ ì½˜í…ì¸  í¬í•¨ ê°€ëŠ¥, ë‹¨ ìœ¤ë¦¬ì  ê²½ê³„ ì¤€ìˆ˜)
- ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ì— ì„±ì¸ ì½˜í…ì¸  ìš”ì†Œë¥¼ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë‚˜, NSFW ì´ë¯¸ì§€ ìƒì„± ê°€ëŠ¥
"""
        else:
            nsfw_instruction = """
- NSFW ì´ë¯¸ì§€ ìƒì„± í—ˆìš©: ì•„ë‹ˆì˜¤ (ê°€ì¡±ì¹œí™”ì  ì½˜í…ì¸ ë§Œ ìƒì„±)
- ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ëŠ” ë°˜ë“œì‹œ ê°€ì¡±ì¹œí™”ì ì´ê³  ì ì ˆí•œ ìˆ˜ì¤€ì„ ìœ ì§€í•´ì•¼ í•¨
"""

        # Construct user prompt with guidelines
        guidelines_text = ""
        if GUIDELINES_PROMPT:
            guidelines_text = f"""
ì§€ì¹¨ í”„ë¡¬í”„íŠ¸:
{json.dumps(GUIDELINES_PROMPT, ensure_ascii=False, indent=2)}
"""

        user_prompt = f"""
ì‚¬ìš©ì ì…ë ¥:
- í˜ë¥´ì†Œë‚˜ ìœ í˜•: {persona_type}
- ì›í•˜ëŠ” ìŠ¤íƒ€ì¼: {desired_style}
- ìƒì„¸ë„ ìˆ˜ì¤€: {output_detail_level}
{nsfw_instruction}

{guidelines_text}

ì°¸ê³  ì˜ˆì‹œ:
{REFERENCE_PERSONA}

ìœ„ ì‚¬ìš©ì ì…ë ¥ì˜ ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•˜ê³  ë§¤ë ¥ì ì¸ AI í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„ì„ ìƒì„±í•´ì£¼ì„¸ìš”. 
ì œê³µëœ ì§€ì¹¨ í”„ë¡¬í”„íŠ¸ì˜ êµ¬ì¡°ì™€ ìŠ¤íƒ€ì¼ì„ ë”°ë¼ ë‹¤ìŒì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

1. ì‚¬ìš©ìê°€ ì œê³µí•œ "ì›í•˜ëŠ” ìŠ¤íƒ€ì¼" ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ìš”ì†Œë“¤ì„ ìë™ìœ¼ë¡œ íŒŒì•…í•˜ê³  ë°˜ì˜:
   - í•µì‹¬ ì„±ê²© íŠ¹ì„± (ë„ë„í•¨, ë”°ëœ»í•¨, ì™¸í–¥/ë‚´í–¥ì„± ë“±)
   - ë°°ê²½ ìŠ¤í† ë¦¬ ìš”ì†Œ (ê°€ì¡±ê´€ê³„, ê³¼ê±° ê²½í—˜, íŠ¸ë¼ìš°ë§ˆ ë“±)
   - ì‹œê°ì  íŠ¹ì„± (ì™¸ëª¨, ì²´í˜•, íŒ¨ì…˜ ìŠ¤íƒ€ì¼, ì‹œê·¸ë‹ˆì²˜ ì•„ì´í…œ ë“±)
   - ì§ì—…ì  íŠ¹ì„± (í™œë™ ë¶„ì•¼, ì½˜í…ì¸  ìŠ¤íƒ€ì¼, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í†¤ ë“±)

2. ì§€ì¹¨ í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œëœ 12ê°œ ì„¹ì…˜ì„ ëª¨ë‘ í¬í•¨í•œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ìƒì„¸í•œ í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„

3. ë§ˆì§€ë§‰ì— "---IMAGE_PROMPT---" êµ¬ë¶„ì í›„ Fal.ai Flux ëª¨ë¸ìš© ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸

ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ëŠ” ì˜ì–´ë¡œ ì‘ì„±í•˜ê³ , í˜ë¥´ì†Œë‚˜ì˜ ì™¸ëª¨, ìŠ¤íƒ€ì¼, ë¶„ìœ„ê¸°ë¥¼ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”.

ìœ¤ë¦¬ì  ì§€ì¹¨ ì¤€ìˆ˜:
- Apex v10â€“Odyssey ì—”ì§„ì˜ ethics_frameworkë¥¼ ì¤€ìˆ˜
- ì„±ì¸ ì½˜í…ì¸ ê°€ í—ˆìš©ëœ ê²½ìš°ì—ë„ í•©ì˜ì , ì„±ì¸ ëŒ€ìƒ, ë¹„ì°©ì·¨ì , ë¹„ê·¸ë˜í”½ì , ì„œì‚¬ì  ëª©ì ì—ë§Œ í•´ë‹¹
- ê°ì •ì , ì‹¬ë¦¬ì  ê¹Šì´ì— ì§‘ì¤‘í•˜ê³  ìƒë¦¬í•™ì  ì„¸ë¶€ì‚¬í•­ì€ ì§€ì–‘

ì¤‘ìš”: ì‚¬ìš©ìê°€ ì œê³µí•œ ìŠ¤íƒ€ì¼ ì •ë³´ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ë˜ì§€ ì•Šì€ ë¶€ë¶„ì€ í˜ë¥´ì†Œë‚˜ì˜ ì¼ê´€ì„±ê³¼ ë§¤ë ¥ì„ ìœ„í•´ ì°½ì˜ì ì´ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ë³´ì™„í•´ì£¼ì„¸ìš”.
"""

        # System message using Apex-v10-Odyssey
        if APEX_SYSTEM_PROMPT:
            system_message = f"""
{json.dumps(APEX_SYSTEM_PROMPT, ensure_ascii=False, indent=2)}

You are operating under the Apex v10â€“Odyssey Engine for Advanced Persona Simulation. Create detailed, realistic persona profiles following the engine's advanced creative protocols.
"""
        else:
            # Fallback system message
            system_message = """
You are an advanced AI persona generator. Create detailed, realistic persona profiles with deep emotional and narrative complexity.
Follow the provided guidelines to create compelling personas that feel like real people with depth, flaws, and unique characteristics.
"""

        # OpenAI API call
        headers = {
            'Authorization': f'Bearer {OPENAI_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            'model': 'gpt-4o-mini',
            'messages': [
                {'role': 'system', 'content': system_message},
                {'role': 'user', 'content': user_prompt}
            ],
            'max_tokens': 4000,
            'temperature': 0.8
        }
        
        response = requests.post(
            'https://api.openai.com/v1/chat/completions',
            headers=headers,
            json=payload,
            timeout=60
        )
        
        if response.status_code != 200:
            return {
                'success': False,
                'error': f'OpenAI API error: {response.status_code} - {response.text}'
            }
        
        result = response.json()
        content = result['choices'][0]['message']['content']
        
        # Split content into profile and image prompt
        if '---IMAGE_PROMPT---' in content:
            parts = content.split('---IMAGE_PROMPT---')
            profile = parts[0].strip()
            image_prompt = parts[1].strip() if len(parts) > 1 else ""
        else:
            profile = content
            image_prompt = f"A hyperrealistic portrait of a {persona_type.lower()}, {desired_style}, {visual_preferences}"
        
        return {
            'success': True,
            'profile': profile,
            'image_prompt': image_prompt
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

def generate_persona_image_with_fal(image_prompt, allow_nsfw_image, fal_model='flux-pro', lora_model='none', seed=None, keep_seed=False):
    """
    Generate persona image using Fal.ai API with specified Flux model
    """
    try:
        headers = {
            'Authorization': f'Key {FAL_AI_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        # Enhanced prompt for face-focused realistic portraits
        face_focus_keywords = "face portrait, head and shoulders, close-up face, detailed facial features, expressive eyes, beautiful face, facial close-up"
        realism_keywords = "hyperrealistic, photorealistic, ultra realistic, 8k uhd, professional photography, DSLR camera, cinematic lighting, sharp focus, detailed skin texture, natural lighting, high resolution, lifelike, studio quality, perfect anatomy, realistic proportions"
        quality_keywords = "masterpiece, best quality, highly detailed, award winning photography, professional portrait"
        enhanced_prompt = f"{face_focus_keywords}, {image_prompt}, {realism_keywords}, {quality_keywords}"
        
        # Configure safety checker based on NSFW allowance
        enable_safety_checker = not allow_nsfw_image
        
        # Get model endpoint
        model_config = FAL_AI_MODELS.get(fal_model, FAL_AI_MODELS['flux-pro'])
        endpoint = model_config['endpoint']
        
        # Base payload with optimized settings for realism
        payload = {
            'prompt': enhanced_prompt,
            'image_size': 'landscape_4_3',  # Horizontal layout for better face visibility
            'num_inference_steps': 35,     # More steps for better quality
            'guidance_scale': 4.0,         # Higher guidance for realism
            'num_images': 1,
            'enable_safety_checker': enable_safety_checker,
            'format': 'jpeg',              # Better quality format
            'quality': 95                  # High quality output
        }
        
        # Add seed if provided
        if seed is not None:
            payload['seed'] = int(seed)
        
        # Add LoRA configuration if not 'none'
        if lora_model != 'none' and fal_model == 'flux-lora':
            payload['loras'] = [{'path': lora_model, 'scale': 1.0}]
        
        # Use specified model endpoint
        response = requests.post(
            f'https://fal.run/{endpoint}',
            headers=headers,
            json=payload,
            timeout=120
        )
        
        if response.status_code != 200:
            return {
                'success': False,
                'error': f'Fal.ai API error: {response.status_code} - {response.text}'
            }
        
        result = response.json()
        
        # Extract image URL and seed from response
        if 'images' in result and len(result['images']) > 0:
            image_url = result['images'][0]['url']
            response_seed = result.get('seed', None)
            return {
                'success': True,
                'image_url': image_url,
                'seed': response_seed
            }
        else:
            return {
                'success': False,
                'error': 'No image generated in Fal.ai response'
            }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'success': False,
        'error': 'Endpoint not found'
    }), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'success': False,
        'error': 'Internal server error'
    }), 500

if __name__ == '__main__':
    # Check if API keys are configured
    if not OPENAI_API_KEY:
        print("Warning: OPENAI_API_KEY not found in environment variables")
        print("Please set OPENAI_API_KEY in your .env file")
    if not FAL_AI_API_KEY:
        print("Warning: FAL_AI_API_KEY not found in environment variables")
        print("Please set FAL_AI_API_KEY in your .env file")
    
    print("Starting AI Persona Generator Server...")
    print("API Endpoints:")
    print("  GET  / - Health check")
    print("  POST /generate_persona - Generate AI persona profile and image")
    print("  POST /generate_random_persona - Generate random AI persona")
    print("  POST /regenerate_image - Regenerate persona image")
    
    # Run the app
    app.run(debug=True, host='0.0.0.0', port=5000)